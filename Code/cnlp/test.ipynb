{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T14:01:22.510343Z",
     "start_time": "2025-05-09T14:01:22.503772Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",  # <- ersetzen\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "\n",
    "# === ðŸ“‹ Modelle definieren ===\n",
    "MODELS = {\n",
    "    \"gpt-4\": \"openai/gpt-4\",\n",
    "    \"claude-3-opus\": \"anthropic/claude-3-opus\",\n",
    "    \"llama-3-70b\": \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"mistral-7b\": \"mistralai/mistral-7b-instruct\",\n",
    "}\n",
    "\n",
    "\n",
    "def run_prompt(model, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-09T14:01:23.357114Z",
     "start_time": "2025-05-09T14:01:23.308763Z"
    }
   },
   "id": "705a88810c2eac81"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === ðŸ§± Produktbeschreibung aus Gruppe erzeugen ===\n",
    "def create_product_description(group):\n",
    "    lines = []\n",
    "    for _, row in group.iterrows():\n",
    "        line = f\"{row['PropertyDefinition']}: {row['PropertyValue']}\"\n",
    "        if pd.notnull(row['UnitName']):\n",
    "            line += f\" {row['UnitName']}\"\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# === ðŸ§¾ Prompt vorbereiten ===\n",
    "def generate_prompt_from_group(group):\n",
    "    product_text = create_product_description(group)\n",
    "    return f\"\"\"\n",
    "Sag mal hallo\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-09T14:01:24.362339Z",
     "start_time": "2025-05-09T14:01:24.353370Z"
    }
   },
   "id": "c0b01020d804ab79"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "# === ðŸš€ Main-Skript ===\n",
    "def main():\n",
    "    # ðŸ”„ Datei laden\n",
    "    df = pd.read_parquet(\"/Users/ilyas/Desktop/FHNW/4. Semester/Challenge/241212_processedproperties_fhnw.parquet\")  # Passe Dateinamen an\n",
    "    grouped = df.groupby(\"ProductId\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for product_id, group in list(grouped)[:5]:  # Nur erste 5 Produkte\n",
    "        prompt = generate_prompt_from_group(group)\n",
    "        row_result = {\"ProductId\": product_id, \"Prompt\": prompt}\n",
    "\n",
    "        for name, model_id in MODELS.items():\n",
    "            try:\n",
    "                print(f\"â³ Anfrage an {name} fÃ¼r Produkt {product_id}...\")\n",
    "                output = run_prompt(model_id, prompt)\n",
    "                row_result[f\"output_{name}\"] = output\n",
    "                time.sleep(1.5)  # Vermeidung von Rate Limits\n",
    "            except Exception as e:\n",
    "                row_result[f\"output_{name}\"] = f\"Fehler: {str(e)}\"\n",
    "\n",
    "        results.append(row_result)\n",
    "\n",
    "    # ðŸ’¾ Speichern\n",
    "    pd.DataFrame(results).to_csv(\"llm_vergleich_resultate.csv\", index=False)\n",
    "    print(\"âœ… Ergebnisse gespeichert unter 'llm_vergleich_resultate.csv'.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-09T14:03:05.836769Z",
     "start_time": "2025-05-09T14:03:05.823843Z"
    }
   },
   "id": "f3dcf94cf17718b6"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Anfrage an gpt-4 fÃ¼r Produkt 200440...\n",
      "â³ Anfrage an claude-3-opus fÃ¼r Produkt 200440...\n",
      "â³ Anfrage an llama-3-70b fÃ¼r Produkt 200440...\n",
      "â³ Anfrage an mistral-7b fÃ¼r Produkt 200440...\n",
      "â³ Anfrage an gpt-4 fÃ¼r Produkt 203240...\n",
      "â³ Anfrage an claude-3-opus fÃ¼r Produkt 203240...\n",
      "â³ Anfrage an llama-3-70b fÃ¼r Produkt 203240...\n",
      "â³ Anfrage an mistral-7b fÃ¼r Produkt 203240...\n",
      "â³ Anfrage an gpt-4 fÃ¼r Produkt 204460...\n",
      "â³ Anfrage an claude-3-opus fÃ¼r Produkt 204460...\n",
      "â³ Anfrage an llama-3-70b fÃ¼r Produkt 204460...\n",
      "â³ Anfrage an mistral-7b fÃ¼r Produkt 204460...\n",
      "â³ Anfrage an gpt-4 fÃ¼r Produkt 207900...\n",
      "â³ Anfrage an claude-3-opus fÃ¼r Produkt 207900...\n",
      "â³ Anfrage an llama-3-70b fÃ¼r Produkt 207900...\n",
      "â³ Anfrage an mistral-7b fÃ¼r Produkt 207900...\n",
      "â³ Anfrage an gpt-4 fÃ¼r Produkt 213020...\n",
      "â³ Anfrage an claude-3-opus fÃ¼r Produkt 213020...\n",
      "â³ Anfrage an llama-3-70b fÃ¼r Produkt 213020...\n",
      "â³ Anfrage an mistral-7b fÃ¼r Produkt 213020...\n",
      "âœ… Ergebnisse gespeichert unter 'llm_vergleich_resultate.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-09T14:09:46.907503Z",
     "start_time": "2025-05-09T14:05:48.472057Z"
    }
   },
   "id": "b5d74a4750f18f58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1a2a2972da8ffd5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
