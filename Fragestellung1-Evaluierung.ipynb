{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-13T15:30:45.057676Z",
     "start_time": "2025-06-13T15:30:45.049660Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionDeniedError\u001B[39m                     Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      1\u001B[39m client = OpenAI(\n\u001B[32m      2\u001B[39m     api_key=\u001B[33m\"\u001B[39m\u001B[33msk-or-v1-63c1a9b70356e612812d6fc5eb618973129596aac5de7b9bbc9079b35bbec80d\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      3\u001B[39m     base_url=\u001B[33m\"\u001B[39m\u001B[33mhttps://openrouter.ai/api/v1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      4\u001B[39m )\n\u001B[32m      6\u001B[39m df = pd.read_csv(\u001B[33m\"\u001B[39m\u001B[33mllm_vergleich_resultate_100_1.csv\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m response = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompletions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mopenai/gpt-3.5-turbo\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Use a lightweight, cheap model\u001B[39;49;00m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrole\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHi! Can you respond with just \u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mYes\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m?\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\n\u001B[32m     12\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(response.choices[\u001B[32m0\u001B[39m].message.content)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPChallenge/venv/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    285\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPChallenge/venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:925\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    882\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    883\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    884\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    922\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m    923\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m    924\u001B[39m     validate_response_format(response_format)\n\u001B[32m--> \u001B[39m\u001B[32m925\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    926\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    927\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    928\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    929\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    933\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    937\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    938\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    939\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    940\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    949\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    954\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    955\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    956\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    957\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    958\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    959\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    960\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    961\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m    962\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m    963\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    964\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    965\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    966\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    967\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    968\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    969\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    970\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPChallenge/venv/lib/python3.11/site-packages/openai/_base_client.py:1239\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1225\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1226\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1227\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1234\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1235\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1236\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1237\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1238\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1239\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/NLPChallenge/venv/lib/python3.11/site-packages/openai/_base_client.py:1034\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1031\u001B[39m             err.response.read()\n\u001B[32m   1033\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1034\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1036\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mPermissionDeniedError\u001B[39m: Error code: 403 - {'error': {'message': 'Key limit exceeded. Manage it using https://openrouter.ai/settings/keys', 'code': 403}}"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"llm_vergleich_resultate_100_1.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-13T16:03:04.322184Z",
     "start_time": "2025-06-13T16:03:01.496696Z"
    }
   },
   "id": "199c346768d5a729"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# === Funktion: Produktbeschreibung aus Gruppe (Parquet) erzeugen ===\n",
    "def create_product_description(group):\n",
    "    lines = []\n",
    "    for _, row in group.iterrows():\n",
    "        line = f\"{row['PropertyDefinition']}: {row['PropertyValue']}\"\n",
    "        if pd.notnull(row['UnitName']):\n",
    "            line += f\" {row['UnitName']}\"\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# === Funktion: Prompt an LLM schicken ===\n",
    "def run_prompt(model, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=700\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# === Bewertungs-Prompt mit fixer Modellreihenfolge erstellen ===\n",
    "def create_evaluation_prompt(product_id, outputs, original_prompt, original_product_text):\n",
    "    prompt = f\"\"\"\n",
    "Du bekommst die Antworten von vier Modellen auf folgenden Prompt:\n",
    "\n",
    "{original_prompt}\n",
    "\n",
    "Die Antworten kommen immer in folgender Reihenfolge:\n",
    "\n",
    "1. GPT-4  \n",
    "2. Claude-3  \n",
    "3. Llama-3  \n",
    "4. Mistral\n",
    "\n",
    "Hier sind die Original-Produktinformationen aus der Parquet-Datei als Referenz:\n",
    "\n",
    "{original_product_text}\n",
    "\n",
    "Bewerte bitte jede JSON-Antwort hinsichtlich:\n",
    "\n",
    "- Ist das JSON technisch valide?\n",
    "- Stimmen die Werte mit den Originaldaten überein?\n",
    "- Sind alle wichtigen Produktspezifikationen enthalten?\n",
    "- Sind die Attributnamen sinnvoll und konsistent?\n",
    "- Wie gut ist die Antwort insgesamt?\n",
    "\n",
    "Produkt {product_id}:\n",
    "\n",
    "Modell 1 (GPT-4) Antwort:\n",
    "{outputs.get('gpt-4', 'Keine Antwort')}\n",
    "\n",
    "Modell 2 (Claude-3) Antwort:\n",
    "{outputs.get('claude-3-opus', 'Keine Antwort')}\n",
    "\n",
    "Modell 3 (Llama-3) Antwort:\n",
    "{outputs.get('llama-3-70b', 'Keine Antwort')}\n",
    "\n",
    "Modell 4 (Mistral) Antwort:\n",
    "{outputs.get('mistral-7b', 'Keine Antwort')}\n",
    "\n",
    "Bewerte jetzt bitte.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# === Hauptprogramm ===\n",
    "def main():\n",
    "    # CSV mit den Modellantworten laden\n",
    "    df_results = pd.read_csv(\"llm_vergleich_resultate_100_1.csv\")\n",
    "\n",
    "    # Parquet-Datei mit Originaldaten laden und gruppieren\n",
    "    df_data = pd.read_parquet(\"241212_processedproperties_fhnw.parquet\")\n",
    "    grouped_data = df_data.groupby(\"ProductId\")\n",
    "\n",
    "    # Modelle fest in Reihenfolge definieren\n",
    "    model_columns = [\n",
    "        \"output_gpt-4\",\n",
    "        \"output_claude-3-opus\",\n",
    "        \"output_llama-3-70b\",\n",
    "        \"output_mistral-7b\"\n",
    "    ]\n",
    "\n",
    "    evaluation_results = []\n",
    "\n",
    "    for idx, row in df_results.iterrows():\n",
    "        product_id = row[\"ProductId\"]\n",
    "        original_prompt = row[\"Prompt\"]\n",
    "\n",
    "        # Originaldaten für das Produkt aus Parquet holen\n",
    "        if product_id in grouped_data.groups:\n",
    "            group = grouped_data.get_group(product_id)\n",
    "            original_product_text = create_product_description(group)\n",
    "        else:\n",
    "            original_product_text = \"Keine Originaldaten gefunden.\"\n",
    "\n",
    "        # Outputs in fester Reihenfolge aus dem CSV extrahieren\n",
    "        outputs = {\n",
    "            \"gpt-4\": row.get(\"output_gpt-4\", \"Keine Antwort\"),\n",
    "            \"claude-3-opus\": row.get(\"output_claude-3-opus\", \"Keine Antwort\"),\n",
    "            \"llama-3-70b\": row.get(\"output_llama-3-70b\", \"Keine Antwort\"),\n",
    "            \"mistral-7b\": row.get(\"output_mistral-7b\", \"Keine Antwort\"),\n",
    "        }\n",
    "\n",
    "        # Bewertungs-Prompt erzeugen\n",
    "        eval_prompt = create_evaluation_prompt(product_id, outputs, original_prompt, original_product_text)\n",
    "\n",
    "        try:\n",
    "            print(f\"Bewerte Produkt {product_id} ...\")\n",
    "            evaluation = run_prompt(\"openai/gpt-4\", eval_prompt)\n",
    "            evaluation_results.append({\"ProductId\": product_id, \"Evaluation\": evaluation})\n",
    "            time.sleep(1.5)  # um Rate Limits zu vermeiden\n",
    "        except Exception as e:\n",
    "            evaluation_results.append({\"ProductId\": product_id, \"Evaluation\": f\"Fehler: {str(e)}\"})\n",
    "\n",
    "    # Ergebnisse speichern\n",
    "    pd.DataFrame(evaluation_results).to_csv(\"llm_evaluation_results.csv\", index=False)\n",
    "    print(\"✅ Bewertung gespeichert in 'llm_evaluation_results.csv'.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-13T15:30:45.172633Z",
     "start_time": "2025-06-13T15:30:45.171334Z"
    }
   },
   "id": "1c48ff184c0219b1"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bewerte Produkt 200440 ...\n",
      "Bewerte Produkt 203240 ...\n",
      "Bewerte Produkt 204460 ...\n",
      "Bewerte Produkt 207900 ...\n",
      "Bewerte Produkt 213020 ...\n",
      "Bewerte Produkt 217400 ...\n",
      "Bewerte Produkt 217880 ...\n",
      "Bewerte Produkt 217920 ...\n",
      "Bewerte Produkt 218940 ...\n",
      "Bewerte Produkt 219760 ...\n",
      "Bewerte Produkt 220700 ...\n",
      "Bewerte Produkt 223540 ...\n",
      "Bewerte Produkt 226180 ...\n",
      "Bewerte Produkt 230800 ...\n",
      "Bewerte Produkt 234280 ...\n",
      "Bewerte Produkt 235640 ...\n",
      "Bewerte Produkt 236020 ...\n",
      "Bewerte Produkt 236480 ...\n",
      "Bewerte Produkt 239420 ...\n",
      "Bewerte Produkt 242680 ...\n",
      "Bewerte Produkt 243500 ...\n",
      "Bewerte Produkt 245840 ...\n",
      "Bewerte Produkt 246660 ...\n",
      "Bewerte Produkt 246740 ...\n",
      "Bewerte Produkt 247340 ...\n",
      "Bewerte Produkt 248360 ...\n",
      "Bewerte Produkt 248500 ...\n",
      "Bewerte Produkt 257900 ...\n",
      "Bewerte Produkt 258140 ...\n",
      "Bewerte Produkt 258300 ...\n",
      "Bewerte Produkt 260700 ...\n",
      "Bewerte Produkt 262100 ...\n",
      "Bewerte Produkt 265340 ...\n",
      "Bewerte Produkt 266020 ...\n",
      "Bewerte Produkt 268560 ...\n",
      "Bewerte Produkt 279960 ...\n",
      "Bewerte Produkt 280680 ...\n",
      "Bewerte Produkt 280720 ...\n",
      "Bewerte Produkt 283500 ...\n",
      "Bewerte Produkt 284400 ...\n",
      "Bewerte Produkt 285780 ...\n",
      "Bewerte Produkt 286140 ...\n",
      "Bewerte Produkt 287640 ...\n",
      "Bewerte Produkt 290880 ...\n",
      "Bewerte Produkt 294740 ...\n",
      "Bewerte Produkt 301820 ...\n",
      "Bewerte Produkt 301860 ...\n",
      "Bewerte Produkt 304980 ...\n",
      "Bewerte Produkt 307320 ...\n",
      "Bewerte Produkt 310520 ...\n",
      "Bewerte Produkt 312780 ...\n",
      "Bewerte Produkt 313220 ...\n",
      "Bewerte Produkt 313800 ...\n",
      "Bewerte Produkt 328040 ...\n",
      "Bewerte Produkt 329180 ...\n",
      "Bewerte Produkt 336440 ...\n",
      "Bewerte Produkt 352820 ...\n",
      "Bewerte Produkt 353220 ...\n",
      "Bewerte Produkt 353500 ...\n",
      "Bewerte Produkt 358140 ...\n",
      "Bewerte Produkt 362020 ...\n",
      "Bewerte Produkt 362400 ...\n",
      "Bewerte Produkt 364120 ...\n",
      "Bewerte Produkt 369500 ...\n",
      "Bewerte Produkt 376280 ...\n",
      "Bewerte Produkt 380240 ...\n",
      "Bewerte Produkt 380660 ...\n",
      "Bewerte Produkt 380800 ...\n",
      "Bewerte Produkt 380820 ...\n",
      "Bewerte Produkt 382280 ...\n",
      "Bewerte Produkt 387700 ...\n",
      "Bewerte Produkt 389620 ...\n",
      "Bewerte Produkt 395320 ...\n",
      "Bewerte Produkt 395780 ...\n",
      "Bewerte Produkt 396000 ...\n",
      "Bewerte Produkt 397480 ...\n",
      "Bewerte Produkt 398340 ...\n",
      "Bewerte Produkt 399820 ...\n",
      "Bewerte Produkt 400560 ...\n",
      "Bewerte Produkt 404820 ...\n",
      "Bewerte Produkt 410220 ...\n",
      "Bewerte Produkt 419620 ...\n",
      "Bewerte Produkt 424500 ...\n",
      "Bewerte Produkt 425240 ...\n",
      "Bewerte Produkt 435020 ...\n",
      "Bewerte Produkt 437460 ...\n",
      "Bewerte Produkt 440620 ...\n",
      "Bewerte Produkt 442780 ...\n",
      "Bewerte Produkt 449540 ...\n",
      "Bewerte Produkt 450600 ...\n",
      "Bewerte Produkt 451120 ...\n",
      "Bewerte Produkt 458200 ...\n",
      "Bewerte Produkt 458600 ...\n",
      "Bewerte Produkt 629560 ...\n",
      "Bewerte Produkt 634780 ...\n",
      "Bewerte Produkt 640340 ...\n",
      "Bewerte Produkt 714480 ...\n",
      "Bewerte Produkt 722560 ...\n",
      "Bewerte Produkt 759480 ...\n",
      "Bewerte Produkt 769880 ...\n",
      "✅ Bewertung gespeichert in 'llm_evaluation_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-13T16:00:32.536702Z",
     "start_time": "2025-06-13T15:30:45.174028Z"
    }
   },
   "id": "bc685a386395dde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
